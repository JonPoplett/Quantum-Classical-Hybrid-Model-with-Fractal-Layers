{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d87b6-fbcc-4adf-95b9-fa6cc2d843bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qutip import basis, Qobj, sesolve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output (optional)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Read and Process the Data (Target Sequence)\n",
    "# =============================================================================\n",
    "\n",
    "def read_target_sequence(csv_file='your_data.csv', column_name='Probability_Vector'):\n",
    "    \"\"\"\n",
    "    Reads the target sequence from a CSV file and processes it into the required format.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file containing your dataset.\n",
    "    - column_name (str): Name of the column containing the probability vectors.\n",
    "\n",
    "    Returns:\n",
    "    - target_sequence (list): List of numpy arrays representing the probability vectors.\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Reading and processing the data...\")\n",
    "    try:\n",
    "        data_df = pd.read_csv(csv_file)\n",
    "        print(\"Data read from CSV:\")\n",
    "        print(data_df.head())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{csv_file}' not found. Please ensure the file exists in the working directory.\")\n",
    "        sys.exit(1)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: '{csv_file}' is empty.\")\n",
    "        sys.exit(1)\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: '{csv_file}' is malformed.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if column_name not in data_df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in '{csv_file}'.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Convert the probability vector column into a list of numpy arrays\n",
    "    try:\n",
    "        # Assuming the probability vectors are stored as strings like \"[0.1, 0.2, ..., 0.0]\"\n",
    "        target_sequence = data_df[column_name].apply(lambda x: np.array(eval(x))).tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing probability vectors: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(f\"Target sequence length: {len(target_sequence)}\")\n",
    "    return target_sequence\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Define the Quantum System\n",
    "# =============================================================================\n",
    "\n",
    "def define_quantum_system(d=34):\n",
    "    \"\"\"\n",
    "    Defines the quantum system's basis states.\n",
    "\n",
    "    Parameters:\n",
    "    - d (int): Dimension of the qudit (default is 34 for the 34-dimensional vectors).\n",
    "\n",
    "    Returns:\n",
    "    - basis_states (list): List of Qobj representing the basis states.\n",
    "    \"\"\"\n",
    "    print(f\"Step 2: Defining quantum system with dimension {d}...\")\n",
    "    basis_states = [basis(d, i) for i in range(d)]\n",
    "    print(f\"{d} basis states defined.\")\n",
    "    return basis_states\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Define the Hamiltonian Components\n",
    "# =============================================================================\n",
    "\n",
    "def define_hamiltonian_components(basis_states, d=34, transition_coeff=1.0, perturbation_strength=0.01):\n",
    "    \"\"\"\n",
    "    Defines projection and transition operators, and constructs the Hamiltonian.\n",
    "\n",
    "    Parameters:\n",
    "    - basis_states (list): List of Qobj representing the basis states.\n",
    "    - d (int): Dimension of the qudit.\n",
    "    - transition_coeff (float): Coefficient for transition operators.\n",
    "    - perturbation_strength (float): Strength of random perturbations to introduce emergent behavior.\n",
    "\n",
    "    Returns:\n",
    "    - operators (list): List of projection operators for each state.\n",
    "    - transition_operators (list): List of transition operators between neighboring states.\n",
    "    - H_grover (function): Function defining the time-dependent Hamiltonian.\n",
    "    \"\"\"\n",
    "    print(\"Step 3: Defining Hamiltonian operators for each state...\")\n",
    "    \n",
    "    # Define projection operators for each state (0 to d-1)\n",
    "    operators = [basis_states[i] * basis_states[i].dag() for i in range(d)]\n",
    "    print(f\"{d} projection operators defined for each state.\")\n",
    "    \n",
    "    # Define transition operators between neighboring states with uniform coefficient\n",
    "    transition_operators = []\n",
    "    for i in range(d - 1):\n",
    "        transition = transition_coeff * (basis_states[i] * basis_states[i + 1].dag() + basis_states[i + 1] * basis_states[i].dag())\n",
    "        transition_operators.append(transition)\n",
    "    \n",
    "    print(f\"Defined {len(transition_operators)} transition operators.\")\n",
    "    \n",
    "    # Define the Hamiltonian function incorporating the target sequence and perturbations\n",
    "    def H_grover(t, args):\n",
    "        \"\"\"\n",
    "        Time-dependent Hamiltonian combining transition and target operators with perturbations.\n",
    "\n",
    "        Parameters:\n",
    "        - t (float): Time variable.\n",
    "        - args (dict): Dictionary containing 'V' (target_sequence) and 'regressive_coeff'.\n",
    "\n",
    "        Returns:\n",
    "        - H_total (Qobj): Total Hamiltonian at time t.\n",
    "        \"\"\"\n",
    "        V = args['V']\n",
    "        regressive_coeff = args['regressive_coeff']\n",
    "        t_int = int(np.floor(t))\n",
    "        if t_int >= len(V):\n",
    "            t_int = len(V) - 1\n",
    "        # Get the probability vector at time t\n",
    "        prob_vector = V[t_int]\n",
    "        \n",
    "        # Base Hamiltonian: sum of transition operators\n",
    "        H_base = sum(transition_operators)\n",
    "        \n",
    "        # Weighted sum of projection operators based on the probability vector\n",
    "        H_target = sum(prob_vector[i] * operators[i] for i in range(d))\n",
    "        \n",
    "        # Sum of regressive coefficients multiplied by their respective operators\n",
    "        H_regressive = sum(regressive_coeff[i] * operators[i] for i in range(d))\n",
    "        \n",
    "        # Introduce a small random perturbation to promote exploration\n",
    "        random_operator = Qobj(np.zeros((d, d)), dims=[[d], [d]])\n",
    "        for _ in range(random.randint(0, 2)):\n",
    "            i = random.randint(0, d - 1)\n",
    "            j = random.randint(0, d - 1)\n",
    "            if i != j and abs(i - j) > 1:\n",
    "                perturbation = random.uniform(-perturbation_strength, perturbation_strength) * (\n",
    "                    basis_states[i] * basis_states[j].dag() + basis_states[j] * basis_states[i].dag()\n",
    "                )\n",
    "                random_operator += perturbation\n",
    "        \n",
    "        # Total Hamiltonian: base + target + regressive + perturbation\n",
    "        H_total = H_base + H_target + H_regressive + random_operator\n",
    "        \n",
    "        # Verify Hermiticity\n",
    "        if not H_total.isherm:\n",
    "            print(\"Warning: Hamiltonian is not Hermitian!\")\n",
    "        \n",
    "        return H_total\n",
    "    \n",
    "    return operators, transition_operators, H_grover\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Set Solver Options\n",
    "# =============================================================================\n",
    "\n",
    "def get_solver_options(atol=1e-6, rtol=1e-6, nsteps=10000, progress_bar=False):\n",
    "    \"\"\"\n",
    "    Defines solver options as a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - atol (float): Absolute tolerance.\n",
    "    - rtol (float): Relative tolerance.\n",
    "    - nsteps (int): Maximum number of integration steps.\n",
    "    - progress_bar (bool): Whether to display a progress bar.\n",
    "\n",
    "    Returns:\n",
    "    - solver_options (dict): Dictionary of solver options.\n",
    "    \"\"\"\n",
    "    solver_options = {\n",
    "        'atol': atol,                # Absolute tolerance\n",
    "        'rtol': rtol,                # Relative tolerance\n",
    "        'nsteps': nsteps,            # Maximum number of integration steps\n",
    "        'progress_bar': progress_bar # Disable progress bar for cleaner output\n",
    "    }\n",
    "    return solver_options\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Initialize the Random Forest Classifier\n",
    "# =============================================================================\n",
    "\n",
    "def initialize_random_forest(n_estimators=100, max_depth=10):\n",
    "    \"\"\"\n",
    "    Initializes the Random Forest classifier for the classical search component.\n",
    "\n",
    "    Parameters:\n",
    "    - n_estimators (int): Number of trees in the forest.\n",
    "    - max_depth (int): Maximum depth of the trees.\n",
    "\n",
    "    Returns:\n",
    "    - rf_classifier (RandomForestClassifier): Initialized Random Forest classifier.\n",
    "    \"\"\"\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    print(\"Random Forest classifier initialized.\")\n",
    "    return rf_classifier\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Assign Fractal Layers to Sequence Positions\n",
    "# =============================================================================\n",
    "\n",
    "def assign_fractal_layers(sequence_length, max_layers):\n",
    "    \"\"\"\n",
    "    Assigns fractal layers to each position in the sequence.\n",
    "\n",
    "    Parameters:\n",
    "    - sequence_length (int): Length of the target sequence.\n",
    "    - max_layers (int): Maximum number of fractal layers.\n",
    "\n",
    "    Returns:\n",
    "    - fractal_layers (list): List assigning each position to a fractal layer.\n",
    "    \"\"\"\n",
    "    fractal_layers = [0] * sequence_length\n",
    "    layer = 1\n",
    "    step = 1\n",
    "    while layer <= max_layers and step < sequence_length:\n",
    "        for i in range(0, sequence_length, step * 2):\n",
    "            if i + step < sequence_length:\n",
    "                fractal_layers[i + step] = layer\n",
    "        layer += 1\n",
    "        step *= 2\n",
    "    return fractal_layers\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Evolve the Quantum-Classical Hybrid System with Fractal Layers\n",
    "# =============================================================================\n",
    "\n",
    "def evolve_system(target_sequence, basis_states, operators, transition_operators, H_grover, \n",
    "                 rf_classifier, fractal_layers, num_runs=10, max_iterations=1000, \n",
    "                 learning_rate=0.05, fractal_regressive_coeff=0.95, \n",
    "                 perturbation_strength=0.01):\n",
    "    \"\"\"\n",
    "    Evolves the quantum-classical hybrid system using Groverâ€™s quantum search, Random Forest, and Fractal Layers.\n",
    "\n",
    "    Parameters:\n",
    "    - target_sequence (list): List of numpy arrays representing the probability vectors.\n",
    "    - basis_states (list): List of Qobj representing the basis states.\n",
    "    - operators (list): List of projection operators.\n",
    "    - transition_operators (list): List of transition operators.\n",
    "    - H_grover (function): Function defining the time-dependent Hamiltonian.\n",
    "    - rf_classifier (RandomForestClassifier): Initialized Random Forest classifier.\n",
    "    - fractal_layers (list): List assigning each position to a fractal layer.\n",
    "    - num_runs (int): Number of independent runs.\n",
    "    - max_iterations (int): Maximum iterations per run.\n",
    "    - learning_rate (float): Rate at which the regressive coefficient is adjusted.\n",
    "    - fractal_regressive_coeff (float): Fixed regressive coefficient for matched positions.\n",
    "    - perturbation_strength (float): Strength of random perturbations.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"Step 7: Evolving the system iteratively with quantum-classical hybrid and fractal layers...\")\n",
    "    \n",
    "    # Define solver options\n",
    "    solver_options = get_solver_options()\n",
    "    \n",
    "    # Initialize the initial state (start with an equal superposition state)\n",
    "    d = len(basis_states)\n",
    "    initial_state = sum(basis_states) / np.sqrt(d)\n",
    "    \n",
    "    # Directory to save CSV files\n",
    "    output_dir = \"simulation_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "        iteration = 0\n",
    "        converged = False\n",
    "        \n",
    "        # Initialize regressive coefficients for each state\n",
    "        regressive_coeffs = {i: 1.0 for i in range(len(basis_states))}  # Start with 1.0 for all\n",
    "        \n",
    "        # Initialize data storage for this run\n",
    "        run_data = []\n",
    "        \n",
    "        # Initialize a set to track matched positions\n",
    "        matched_positions = set()\n",
    "        \n",
    "        while not converged and iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\nIteration {iteration}\")\n",
    "            \n",
    "            # Update args with current regressive coefficients\n",
    "            args = {\n",
    "                'V': target_sequence,\n",
    "                'regressive_coeff': regressive_coeffs  # Dictionary of regressive coefficients\n",
    "            }\n",
    "\n",
    "            # Define time steps for this run\n",
    "            t_list = np.linspace(0, len(target_sequence) - 1, len(target_sequence))\n",
    "        \n",
    "            # Initialize storage for states\n",
    "            states_over_time = []\n",
    "        \n",
    "            # Solve the system using sesolve with defined options\n",
    "            try:\n",
    "                result = sesolve(H_grover, initial_state, t_list, [], args=args, options=solver_options)\n",
    "                states_over_time = result.states\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during sesolve: {e}\")\n",
    "                break\n",
    "\n",
    "            # Initialize a flag to check if all positions have been assigned\n",
    "            all_positions_assigned = True\n",
    "\n",
    "            # Measure at each time step to adjust accordingly\n",
    "            for idx, state in enumerate(states_over_time):\n",
    "                # Calculate measurement probabilities\n",
    "                measurement_probs = [abs(basis_states[i].dag() * state)[0][0][0]**2 for i in range(len(basis_states))]\n",
    "                measured_state = np.argmax(measurement_probs)\n",
    "\n",
    "                # Collect data for Random Forest\n",
    "                position_data = {\n",
    "                    'Run': run,\n",
    "                    'Iteration': iteration,\n",
    "                    'Position': idx,\n",
    "                    'Target_Prob_Vector': target_sequence[idx],\n",
    "                    'Measured_State': measured_state,\n",
    "                    'Fractal_Layer': fractal_layers[idx],\n",
    "                }\n",
    "                # Add measurement probabilities as separate columns\n",
    "                for state_idx, prob in enumerate(measurement_probs):\n",
    "                    position_data[f'Prob_State_{state_idx}'] = prob\n",
    "\n",
    "                run_data.append(position_data)\n",
    "\n",
    "                # Determine if the current position is within the current fractal layer\n",
    "                if fractal_layers[idx] <= iteration:\n",
    "                    # Compare measured state with the highest probability in the target probability vector\n",
    "                    target_state = np.argmax(target_sequence[idx])\n",
    "                    if measured_state == target_state:\n",
    "                        # Set regressive_coeff for matched state to fractal_regressive_coeff\n",
    "                        regressive_coeffs[measured_state] = fractal_regressive_coeff\n",
    "                        matched_positions.add(idx)\n",
    "                        print(f\"Matched state at position {idx}: {measured_state} | Set regressive_coeff to {fractal_regressive_coeff}\")\n",
    "                    else:\n",
    "                        # If not matching, keep regressive_coeff at 1.0 to maintain influence\n",
    "                        all_positions_assigned = False\n",
    "                        print(f\"Mismatch at position {idx}: {measured_state} != {target_state} | regressive_coeff remains at 1.0\")\n",
    "                else:\n",
    "                    # For positions not yet assigned to the current or previous fractal layers\n",
    "                    if measured_state != np.argmax(target_sequence[idx]):\n",
    "                        all_positions_assigned = False\n",
    "\n",
    "            # Print progress update\n",
    "            total_positions = len(target_sequence)\n",
    "            matched_count = len(matched_positions)\n",
    "            print(f\"\\nProgress Update: {matched_count} out of {total_positions} positions have been matched.\")\n",
    "            \n",
    "            # Check for convergence (all positions have been assigned and matched)\n",
    "            if all_positions_assigned and matched_count == total_positions:\n",
    "                print(f\"All positions have been assigned and matched in run {run} after {iteration} iterations!\")\n",
    "                converged = True\n",
    "                # Save the data to CSV\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                csv_filename = f\"Run_{run}_Data_{timestamp}.csv\"\n",
    "                csv_path = os.path.join(output_dir, csv_filename)\n",
    "                df_run.to_csv(csv_path, index=False)\n",
    "                print(f\"Data for run {run} saved to '{csv_path}'.\")\n",
    "                break  # Exit the iteration loop\n",
    "\n",
    "            # Train the Random Forest classifier with accumulated data\n",
    "            if run_data:\n",
    "                # Prepare data for training\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                feature_columns = [f'Prob_State_{i}' for i in range(len(basis_states))]\n",
    "                X_train = df_run[feature_columns]\n",
    "                y_train = df_run['Target_Prob_Vector'].apply(lambda x: np.argmax(x))\n",
    "                \n",
    "                rf_classifier.fit(X_train, y_train)\n",
    "                print(\"Random Forest classifier trained with current data.\")\n",
    "\n",
    "            # Use Random Forest to predict and adjust regressive coefficients\n",
    "            if run_data:\n",
    "                latest_data = run_data[-1]\n",
    "                latest_measurement = np.array([latest_data[f'Prob_State_{i}'] for i in range(len(basis_states))]).reshape(1, -1)\n",
    "                predicted_state = rf_classifier.predict(latest_measurement)[0]\n",
    "                print(f\"Random Forest Prediction for next state: {predicted_state}\")\n",
    "                \n",
    "                # Optionally, adjust regressive_coefficients based on prediction\n",
    "                current_position = latest_data['Position']\n",
    "                target_state = np.argmax(target_sequence[current_position])\n",
    "                if predicted_state != target_state and current_position < len(target_sequence):\n",
    "                    regressive_coeffs[target_state] = fractal_regressive_coeff\n",
    "                    print(f\"Adjusted regressive_coeff for target state {target_state} to {fractal_regressive_coeff} based on prediction.\")\n",
    "\n",
    "        # After all iterations, if not converged, save the data\n",
    "        if not converged:\n",
    "            print(f\"Run {run} did not fully converge after {max_iterations} iterations.\")\n",
    "            if run_data:\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                csv_filename = f\"Run_{run}_Data_{timestamp}.csv\"\n",
    "                csv_path = os.path.join(output_dir, csv_filename)\n",
    "                df_run.to_csv(csv_path, index=False)\n",
    "                print(f\"Partial data for run {run} saved to '{csv_path}'.\")\n",
    "\n",
    "        # After each run, plot the measurement results if converged\n",
    "        if converged and run_data:\n",
    "            measurements = [row['Measured_State'] for row in run_data]\n",
    "            target_states = [np.argmax(seq) for seq in target_sequence]\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(range(len(measurements)), measurements, label='Measured State', marker='o', markersize=4, linewidth=1)\n",
    "            plt.plot(range(len(target_states)), target_states, label='Target State', linestyle='--', marker='x', markersize=4)\n",
    "            plt.xlabel('Position in Sequence')\n",
    "            plt.ylabel('State')\n",
    "            plt.title(f'State Measurements Over Time - Run {run}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No plot generated for run {run}.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Main Execution\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    # Define parameters\n",
    "    csv_file = 'your_data.csv'              # CSV file containing your dataset\n",
    "    column_name = 'Probability_Vector'      # Column name in the CSV file\n",
    "    d = 34                                  # Dimension of the qudit (states 0-33)\n",
    "    num_runs = 10                           # Number of independent runs\n",
    "    max_iterations = 1000                   # Maximum iterations per run\n",
    "    learning_rate = 0.05                    # Learning rate for adjusting regressive_coeff\n",
    "    fractal_regressive_coeff = 0.95         # Fixed regressive coefficient upon successful match\n",
    "    max_layers = 10                         # Maximum number of fractal layers\n",
    "    perturbation_strength = 0.01            # Strength of random perturbations\n",
    "\n",
    "    # Step 1: Read the target sequence\n",
    "    target_sequence = read_target_sequence(csv_file, column_name)\n",
    "    \n",
    "    # Ensure that the probability vectors are normalized\n",
    "    target_sequence = [vec / np.sum(vec) for vec in target_sequence]\n",
    "\n",
    "    # Step 2: Define the quantum system's basis states\n",
    "    basis_states = define_quantum_system(d)\n",
    "    \n",
    "    # Step 3: Define Hamiltonian components (projection and transition operators)\n",
    "    operators, transition_operators, H_grover = define_hamiltonian_components(\n",
    "        basis_states, d, transition_coeff=1.0, perturbation_strength=perturbation_strength\n",
    "    )\n",
    "    \n",
    "    # Step 4: Initialize the Random Forest classifier\n",
    "    rf_classifier = initialize_random_forest()\n",
    "    \n",
    "    # Step 5: Assign fractal layers to sequence positions\n",
    "    fractal_layers = assign_fractal_layers(len(target_sequence), max_layers)\n",
    "    print(\"Fractal layers assigned to sequence positions.\")\n",
    "    \n",
    "    # Optional: Print fractal layer assignments\n",
    "    # for pos, layer in enumerate(fractal_layers):\n",
    "    #     print(f\"Position {pos}: Layer {layer}\")\n",
    "    \n",
    "    # Step 6: Evolve the quantum-classical hybrid system with fractal layers\n",
    "    evolve_system(\n",
    "        target_sequence=target_sequence,\n",
    "        basis_states=basis_states,\n",
    "        operators=operators,\n",
    "        transition_operators=transition_operators,\n",
    "        H_grover=H_grover,\n",
    "        rf_classifier=rf_classifier,\n",
    "        fractal_layers=fractal_layers,\n",
    "        num_runs=num_runs,\n",
    "        max_iterations=max_iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        fractal_regressive_coeff=fractal_regressive_coeff,\n",
    "        perturbation_strength=perturbation_strength\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# Entry Point\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
